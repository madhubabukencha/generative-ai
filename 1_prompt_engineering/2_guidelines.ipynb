{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4917a480-e4d4-44d6-9c19-fcd1ea927f68",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif; \n",
    "          text-align: center;\">\n",
    "          Guidelines</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417e73c-003e-4af9-afdb-b48e543b68e8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">Prerequisites</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587665a-f5ca-42a6-a0f8-a466b35a0d76",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "   To work with <b>Openai</b> api using <b>Python</b>, you need to install openai package\n",
    "   using <code>pip install openai</code> command. OpenAI api key is required to work with\n",
    "   openai API. You can create them in OpenAI website(<a href=\"https://platform.openai.com/account/api-keys\">\n",
    "   api-keys</a>). You can also check your api usage in <a href=\"https://platform.openai.com/usage\">usage</a> page.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0633fd3-f147-4fca-9ac3-fed3bb7e71de",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">Setting up Initial Config</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94953a00-0215-4d44-b571-575a15a801a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ced9b4-90ba-49bb-b23e-31f523f30050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key = os.getenv(\"OPENAI\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537f15e-ced6-4753-af66-db2d31833537",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "       Creating a general function which takes prompt and model as it's inputs and returns the response.\n",
    "       OpenAI offers various models with different capabilities. All those models can be found\n",
    "       <a href=\"https://platform.openai.com/docs/models\">Models</a> section.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf433f5-2ef0-4a21-8f90-aaa79f254ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-2024-05-13\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # temperature: A higher value, such as 0.8, makes the answers more diverse,\n",
    "        # while a lower value, like 0.2, makes them more focused and deterministic.\n",
    "        temperature=0.2, \n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b4a4c-e84d-4c5a-b7ef-1cc948fda8a5",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">Principles of Prompting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c7c24-7bb2-40e6-aa46-2378e8392d61",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "   Principles of prompting helps us to generate better results from model. We have two major principles,\n",
    "   <ul style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "       <li>Write clear & specific instructions</li>\n",
    "       <li>Give the model time to think</li>\n",
    "   </ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544b500-86a9-41f2-bf72-5f0462ff9ffa",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#40A578; font-weight: bold; font-family: cursive\">Principle-1: Write clear & specific instructions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c96e84-6edb-4a5b-97dc-cdc07f7b1834",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family:recursive;\">\n",
    "   <b>Tactic-1</b>: Use delimeters <br>\n",
    "    <ul style=\"text-align: justify; text-justify: inter-word; font-family:recursive;\">\n",
    "        <li>Triple quotes: \"\"\"</li>\n",
    "        <li>Triple backticks: <code>```</code></li>\n",
    "        <li>Triple dashes: ---</li>\n",
    "        <li>Angle brackets: &#60;&#62;</li>\n",
    "        <li>XML tags</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fb8ae9-c375-4345-abde-737d599570ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve the desired output and minimize irrelevant or incorrect responses from a model, provide clear and specific instructions, with longer prompts often offering better clarity and context.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7e965-e2e1-4aab-9b2a-72789f1b644b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "   <b>Tactic-2</b>: Ask for a structured output like in the form of JSON, HTML etc ..,\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803554bc-b9de-485c-a638-9aa7ac9bb7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are three actors with their details in the specified JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"actor_name\": \"Leonardo DiCaprio\",\n",
      "    \"age\": 48,\n",
      "    \"country\": \"United States\"\n",
      "},\n",
      "{\n",
      "    \"actor_name\": \"Emma Watson\",\n",
      "    \"age\": 33,\n",
      "    \"country\": \"United Kingdom\"\n",
      "},\n",
      "{\n",
      "    \"actor_name\": \"Chris Hemsworth\",\n",
      "    \"age\": 40,\n",
      "    \"country\": \"Australia\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Provide 3 actors name, their age and country they belongs to in below specified\n",
    "JSON format.\n",
    "{\n",
    "    'actor_name': <replace with actor name>,\n",
    "    'age': <replace with age>,\n",
    "    'country': <replace with country>\n",
    "}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a77f37-fedc-4eb1-8189-d023c7378499",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "   <b>Tactic-3:</b> Check whether conditions are satisfied\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e74e13-aac4-4278-882e-532c6fc80e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - If you like, add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea.\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b1bb18-e74b-456f-8124-c40e2ee2717f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "The provided text does not contain a sequence of instructions. It is a descriptive passage about a beautiful day in the park. Therefore, there are no steps to re-write in the requested format.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9cb8d-be39-4434-8bb5-e95c8ba9bea3",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "   <b>Tactic-4</b>: Few-Shot Prompting, Give successful examples of completing tasks, then ask\n",
    "   model to perform the task\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf0f27d-4277-4ded-b106-ac652e929785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: The mighty oak stands tall through countless storms, its roots digging deeper with each gust of wind; the phoenix rises from its ashes, reborn and renewed; the diamond, forged under immense pressure, emerges unbreakable and brilliant.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28d2eb-2aee-4b37-ac4a-4c5912cfcab9",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#40A578; font-weight: bold; font-family: cursive\">Principle - 2: Give the model time to think</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4bbc8-2de9-46f9-a4df-48f895c3f696",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "    <b>Tactic - 1:</b> Specify the steps to complete a task\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e907cf-69d3-4e79-b0de-86e7baa54288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "1 - Siblings Jack and Jill embarked on a quest to fetch water from a hilltop well, but after Jack tripped and they both tumbled down, they returned home slightly battered yet undeterred in their adventurous spirits.\n",
      "\n",
      "2 - Les frères et sœurs Jack et Jill se sont lancés dans une quête pour chercher de l'eau à un puits au sommet d'une colline, mais après que Jack ait trébuché et qu'ils soient tous deux tombés, ils sont rentrés chez eux légèrement meurtris mais toujours déterminés dans leur esprit d'aventure.\n",
      "\n",
      "3 - Jack, Jill\n",
      "\n",
      "4 - \n",
      "```json\n",
      "{\n",
      "  \"french_summary\": \"Les frères et sœurs Jack et Jill se sont lancés dans une quête pour chercher de l'eau à un puits au sommet d'une colline, mais après que Jack ait trébuché et qu'ils soient tous deux tombés, ils sont rentrés chez eux légèrement meurtris mais toujours déterminés dans leur esprit d'aventure.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5feee4b6-85bb-419b-9d62-794d21e64ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Summary: In a charming village, siblings Jack and Jill set out to fetch water from a hilltop well, but after Jack tripped and tumbled down the hill with Jill following, they returned home slightly battered but still adventurous.\n",
      "\n",
      "Translation: Dans un charmant village, les frères et sœurs Jack et Jill sont partis chercher de l'eau à un puits au sommet d'une colline, mais après que Jack ait trébuché et dévalé la colline avec Jill le suivant, ils sont rentrés chez eux légèrement meurtris mais toujours aventureux.\n",
      "\n",
      "Names: Jack, Jill\n",
      "\n",
      "Output JSON: \n",
      "{\n",
      "  \"french_summary\": \"Dans un charmant village, les frères et sœurs Jack et Jill sont partis chercher de l'eau à un puits au sommet d'une colline, mais après que Jack ait trébuché et dévalé la colline avec Jill le suivant, ils sont rentrés chez eux légèrement meurtris mais toujours aventureux.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Asking for the output in the specified format\n",
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in Italian summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de94884-1121-4c63-b71e-858a5cbe2844",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "       <b>Tactic - 2</b>: Instruct the model to workout it own solution before rushing to conclusion.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1ed9f6-1ab3-485f-a2ff-6e3042491f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct. Let's break down the costs and verify the total cost for the first year of operations as a function of the number of square feet \\( x \\).\n",
      "\n",
      "1. **Land cost**: The cost of the land is $100 per square foot. Therefore, for \\( x \\) square feet, the land cost is:\n",
      "   \\[\n",
      "   100x\n",
      "   \\]\n",
      "\n",
      "2. **Solar panel cost**: The cost of the solar panels is $250 per square foot. Therefore, for \\( x \\) square feet, the solar panel cost is:\n",
      "   \\[\n",
      "   250x\n",
      "   \\]\n",
      "\n",
      "3. **Maintenance cost**: The maintenance cost consists of a flat fee of $100,000 per year plus an additional $10 per square foot. Therefore, for \\( x \\) square feet, the maintenance cost is:\n",
      "   \\[\n",
      "   100,000 + 10x\n",
      "   \\]\n",
      "\n",
      "Adding these costs together, we get the total cost for the first year of operations:\n",
      "\\[\n",
      "100x + 250x + 100,000 + 10x\n",
      "\\]\n",
      "\n",
      "Combining like terms, we get:\n",
      "\\[\n",
      "(100 + 250 + 10)x + 100,000 = 360x + 100,000\n",
      "\\]\n",
      "\n",
      "Therefore, the total cost for the first year of operations as a function of the number of square feet \\( x \\) is:\n",
      "\\[\n",
      "360x + 100,000\n",
      "\\]\n",
      "\n",
      "The student's solution is indeed correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet. return response in latex syntax\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca0dc04-aa87-4c66-9598-4edfcc213e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: $100 per square foot, so the total land cost is 100x.\n",
      "2. Solar panel cost: $250 per square foot, so the total solar panel cost is 250x.\n",
      "3. Maintenance cost: A flat $100,000 per year plus $10 per square foot, so the total maintenance cost is 100,000 + 10x.\n",
      "\n",
      "Total cost for the first year:\n",
      "Land cost + Solar panel cost + Maintenance cost\n",
      "= 100x + 250x + (100,000 + 10x)\n",
      "= 100x + 250x + 100,000 + 10x\n",
      "= 360x + 100,000\n",
      "\n",
      "Therefore, the total cost for the first year of operations as a function of the number of square feet is 360x + 100,000.\n",
      "```\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "No\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "Incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30dad8-8954-4e51-9fe0-0cb40aa25b57",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">Model Limitations</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a0a36-e82b-4456-875f-96502feb6564",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word; font-family: cursive;\">\n",
    "    <b>Hallucination</b> makes statements that sound possible but are not true.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54453f67-da71-4fcb-97ce-3b2922664a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, there is no specific product known as the \"AeroGlide UltraSlim Smart Toothbrush by Boie.\" It's possible that this product was released after my last update or it might be a hypothetical or conceptual product.\n",
      "\n",
      "However, Boie USA is known for its eco-friendly and innovative personal care products, including toothbrushes. Boie's toothbrushes are typically made from a durable, antimicrobial material that is designed to last longer than traditional toothbrushes, reducing waste. They often feature replaceable heads to further minimize environmental impact.\n",
      "\n",
      "If \"AeroGlide UltraSlim Smart Toothbrush\" is a new product, it might combine advanced features such as:\n",
      "\n",
      "1. **UltraSlim Design**: A sleek and slim profile for better handling and reach.\n",
      "2. **Smart Technology**: Integration with a mobile app for tracking brushing habits, providing feedback, and possibly offering personalized brushing tips.\n",
      "3. **Eco-Friendly Materials**: Continuing Boie's commitment to sustainability with recyclable or biodegradable materials.\n",
      "4. **Antimicrobial Properties**: To keep the toothbrush cleaner and more hygienic.\n",
      "5. **Replaceable Heads**: To reduce waste and extend the life of the toothbrush.\n",
      "\n",
      "For the most accurate and up-to-date information, I recommend checking Boie USA's official website or contacting their customer service directly.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339a156-32ab-4256-88bb-fdd782e53286",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify; text-justify: inter-word;font-family:cursive;\">\n",
    "   To reduce hallucinations, ask model first to find relavent information then answer the question based on the\n",
    "   relavent information.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd1dce0-fe8c-4e18-bb23-a03ac376ff61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have the information.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Condition: \n",
    "Do fact check, if you found relavent information then only tell me about\\\n",
    "or else simple mention you don't have the information\n",
    "\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573bf56-46c4-4288-8f11-1ccba2be02a9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">General Questions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1c7b93f-215a-46c7-b314-5fb39f47c1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a table listing some free large language models:\n",
      "\n",
      "| Model Name          | Developer/Organization | Description                                                                 | Access Link                                      |\n",
      "|---------------------|------------------------|-----------------------------------------------------------------------------|-------------------------------------------------|\n",
      "| GPT-3               | OpenAI                 | A powerful language model with 175 billion parameters.                      | [OpenAI GPT-3](https://beta.openai.com/signup/)  |\n",
      "| GPT-2               | OpenAI                 | A smaller version of GPT-3 with 1.5 billion parameters.                     | [OpenAI GPT-2](https://github.com/openai/gpt-2)  |\n",
      "| BERT                | Google                 | Bidirectional Encoder Representations from Transformers.                    | [BERT](https://github.com/google-research/bert)  |\n",
      "| RoBERTa             | Facebook AI            | A robustly optimized BERT approach.                                         | [RoBERTa](https://github.com/pytorch/fairseq)    |\n",
      "| T5                  | Google                 | Text-To-Text Transfer Transformer.                                          | [T5](https://github.com/google-research/text-to-text-transfer-transformer) |\n",
      "| DistilBERT          | Hugging Face           | A smaller, faster, cheaper version of BERT.                                 | [DistilBERT](https://github.com/huggingface/transformers) |\n",
      "| GPT-Neo             | EleutherAI             | An open-source alternative to GPT-3.                                        | [GPT-Neo](https://github.com/EleutherAI/gpt-neo) |\n",
      "| GPT-J               | EleutherAI             | A 6 billion parameter model, open-source.                                   | [GPT-J](https://github.com/kingoflolz/mesh-transformer-jax) |\n",
      "| XLNet               | Google/CMU             | Generalized autoregressive pretraining for language understanding.          | [XLNet](https://github.com/zihangdai/xlnet)      |\n",
      "| ALBERT              | Google                 | A Lite BERT for self-supervised learning of language representations.        | [ALBERT](https://github.com/google-research/albert) |\n",
      "| CTRL                | Salesforce             | A conditional transformer language model for controllable generation.       | [CTRL](https://github.com/salesforce/ctrl)       |\n",
      "| OpenAI Codex        | OpenAI                 | A descendant of GPT-3, specialized for coding tasks.                        | [OpenAI Codex](https://beta.openai.com/signup/)  |\n",
      "\n",
      "Please note that while these models are free to use, some may require you to sign up or agree to certain terms and conditions. Additionally, the availability and terms of use can change, so it's always a good idea to check the official sources for the most current information.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Can you list free large language models in a table format?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dfe5677-48bb-4424-8a95-add049739fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Fine-tuning a BERT model using PyTorch involves several steps, including loading the pre-trained BERT model, preparing the dataset, defining the training loop, and evaluating the model. Below is a complete example of how to fine-tune a BERT model for a text classification task using the `transformers` library by Hugging Face, which provides an easy interface for working with BERT and other transformer models.\n",
      "\n",
      "First, make sure you have the necessary libraries installed:\n",
      "```bash\n",
      "pip install torch transformers datasets\n",
      "```\n",
      "\n",
      "Here's a complete example:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "from torch.utils.data import DataLoader\n",
      "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
      "from datasets import load_dataset\n",
      "import numpy as np\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Load dataset\n",
      "dataset = load_dataset('glue', 'mrpc')\n",
      "\n",
      "# Load pre-trained BERT tokenizer\n",
      "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
      "\n",
      "# Tokenize the dataset\n",
      "def tokenize_function(examples):\n",
      "    return tokenizer(examples['sentence1'], examples['sentence2'], padding='max_length', truncation=True)\n",
      "\n",
      "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
      "\n",
      "# Convert to PyTorch tensors\n",
      "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
      "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
      "\n",
      "# Create DataLoader\n",
      "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=8)\n",
      "eval_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=8)\n",
      "\n",
      "# Load pre-trained BERT model\n",
      "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
      "\n",
      "# Set up optimizer and learning rate scheduler\n",
      "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
      "num_epochs = 3\n",
      "num_training_steps = num_epochs * len(train_dataloader)\n",
      "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
      "\n",
      "# Training loop\n",
      "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
      "model.to(device)\n",
      "\n",
      "for epoch in range(num_epochs):\n",
      "    model.train()\n",
      "    for batch in train_dataloader:\n",
      "        batch = {k: v.to(device) for k, v in batch.items()}\n",
      "        outputs = model(**batch)\n",
      "        loss = outputs.loss\n",
      "        loss.backward()\n",
      "        \n",
      "        optimizer.step()\n",
      "        lr_scheduler.step()\n",
      "        optimizer.zero_grad()\n",
      "    \n",
      "    # Evaluation loop\n",
      "    model.eval()\n",
      "    all_predictions = []\n",
      "    all_labels = []\n",
      "    for batch in eval_dataloader:\n",
      "        batch = {k: v.to(device) for k, v in batch.items()}\n",
      "        with torch.no_grad():\n",
      "            outputs = model(**batch)\n",
      "        \n",
      "        logits = outputs.logits\n",
      "        predictions = torch.argmax(logits, dim=-1)\n",
      "        all_predictions.extend(predictions.cpu().numpy())\n",
      "        all_labels.extend(batch['labels'].cpu().numpy())\n",
      "    \n",
      "    accuracy = accuracy_score(all_labels, all_predictions)\n",
      "    print(f\"Epoch {epoch + 1}/{num_epochs}, Accuracy: {accuracy:.4f}\")\n",
      "\n",
      "# Save the fine-tuned model\n",
      "model.save_pretrained('./fine_tuned_bert')\n",
      "tokenizer.save_pretrained('./fine_tuned_bert')\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Dataset Loading**: We use the `datasets` library to load the MRPC dataset from the GLUE benchmark.\n",
      "2. **Tokenization**: We tokenize the sentences using the BERT tokenizer.\n",
      "3. **DataLoader**: We create DataLoader objects for the training and validation datasets.\n",
      "4. **Model Loading**: We load a pre-trained BERT model for sequence classification.\n",
      "5. **Optimizer and Scheduler**: We set up the AdamW optimizer and a learning rate scheduler.\n",
      "6. **Training Loop**: We fine-tune the model over several epochs, updating the model weights.\n",
      "7. **Evaluation Loop**: We evaluate the model on the validation set and compute accuracy.\n",
      "8. **Saving the Model**: Finally, we save the fine-tuned model and tokenizer.\n",
      "\n",
      "This script provides a basic framework for fine-tuning BERT on a text classification task. You can customize it further based on your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Write a program using PyTorch for finetuning bert model?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc995884-b0ad-4c2c-b9fe-3bada0b34e9d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold; font-family: cursive\">Creating Image using Image Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d51445e-e61b-44aa-b9a1-18bd1af84927",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"\"\"Generate a beautiful house with nice lighting, modern architecture and branded cars parking infornt of the\n",
    "    house. Generate cenematic image\"\"\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c79c4324-cbe0-4498-a2f4-74c51fa474f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-e9laCYQS1BO3IlcUuS2ApQw4/user-UeLVQ69dCGvgki6kSyzh6Wyj/img-syOt2UYzlNQUmFPtK7JKc6R5.png?st=2024-07-05T06%3A48%3A07Z&se=2024-07-05T08%3A48%3A07Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-05T01%3A50%3A59Z&ske=2024-07-06T01%3A50%3A59Z&sks=b&skv=2023-11-03&sig=dew4NVUHZ2RGIjFyrWzGE3iCXDGmT2h%2BEOPPMfuMn3Q%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Assuming your variable containing the image URL is named 'image_url'\n",
    "image_to_display = Image(url=image_url)\n",
    "display(image_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2023f6-7927-4906-9d5c-da6932dba662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
