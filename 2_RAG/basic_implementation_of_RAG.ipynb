{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829ecc48-7793-4426-8c38-c083043054a7",
   "metadata": {},
   "source": [
    "<p style=\"color:#153462; \n",
    "          font-weight: bold; \n",
    "          font-size: 30px; \n",
    "          font-family: Gill Sans, sans-serif;\n",
    "          text-align: center;\">\n",
    "          Basic Implemetation of RAG</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328cc07-4d89-4af0-a185-e5b25ccd888c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold;\">Required Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1daf7a88-588f-487f-a25c-f7cbc2f20af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "from chromadb.utils import embedding_functions\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cf1af-4d51-41f1-bcaa-97f69282f383",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold;\">Setting up the Environment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde7a283-b1c9-428d-9d0e-0601e13f656a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key = openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab70a58-7f5a-4041-9628-a23f7363533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=openai_key,\n",
    "            model_name=\"text-embedding-3-small\" \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56241be4-1078-47c3-8e4f-9e49ccdfd56d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold;\">Setting up Chromadb</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969f636c-cd83-40dd-a43f-a183e4ff6b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chromadb_client = chromadb.PersistentClient(path=\"chroma_persistant_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0402b8aa-23bc-4be8-8f12-a64c2c51327c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_name = \"document_qa_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c0dce1-86db-4e65-b9f3-e1a7a34c3e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = chromadb_client.get_or_create_collection(name=collection_name, embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8224c-8551-479f-b847-c856a51e54b8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold;\">Loading Documents</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582f6dfa-9636-47e3-af64-a4abf677f68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_documents_from_directory(dir_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Function which reads the text from documents and stores in the list of dictories\n",
    "    \n",
    "    :param dir_path: Directory of text documents\n",
    "    :type  dir_path: str\n",
    "    \n",
    "    :returns : List of directories which holds extracted text\n",
    "    :rtype: list[dict]\n",
    "    \"\"\"\n",
    "    print(\"Loading documents...\")\n",
    "    documents = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(file=os.path.join(directory_path, filename), mode=\"r\", encoding=\"utf-8\") as file:\n",
    "                documents.append({\"id\": filename, \"text\": file.read()})\n",
    "        count += 1\n",
    "    print(f\"Loading Completed. Loaded {count} documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ea4040-7d42-4c01-a1af-7c226929a496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text(text: str, chunk_size: int=1000, chunk_overlap: int=20) -> list[str]:\n",
    "    \"\"\"\n",
    "    Function which creates a chunks of given text\n",
    "    \n",
    "    :param text: Text\n",
    "    :type  text: str\n",
    "    :param chunk_size: Large text divided into provide chunk size\n",
    "    :type  chunk_size: int\n",
    "    :param chunk_overlap: Which is the text overlap between chunk to next chunk. Helps in keep good context\n",
    "    :type  chunk_overlap: int\n",
    "    \n",
    "    :returns: List of string of specified chunk_size\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start <= len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start: end])\n",
    "        start = end - chunk_overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd0549e-7ebc-4e77-be67-85dc23723984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loading Completed. Loaded 21 documents\n"
     ]
    }
   ],
   "source": [
    "# Load documents from the directory\n",
    "directory_path = \"./news_articles\"\n",
    "documents = load_documents_from_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830ef940-cfd3-46ac-8f6a-a026dd09bb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating chunks data...\n",
      "Creating chunks data is completed. Total chunks: 184\n"
     ]
    }
   ],
   "source": [
    "# Creating chunks\n",
    "chunked_documents = []\n",
    "print(\"Creating chunks data...\")\n",
    "for doc in documents:\n",
    "    chunks = split_text(doc[\"text\"])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_documents.append({\"id\": f\"{doc['id']}_chunk{i+1}\", \"text\": chunk})\n",
    "print(f\"Creating chunks data is completed. Total chunks: {len(chunked_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b79cf0-6090-41cf-a4f1-4e6f0ae64844",
   "metadata": {},
   "source": [
    "### <span style=\"color:#C738BD; font-weight: bold;\">Creating Embeddings and Insterting in Chromadb</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49411338-6740-43ce-a0dd-2e27ff876e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to generate embeddings using OpenAI API\n",
    "def get_openai_embedding(text: str):\n",
    "    response = client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dac1e14-b300-4a25-a986-211e76bbb29b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [01:30<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the document chunks\n",
    "# for doc in tqdm(chunked_documents):\n",
    "#     doc[\"embedding\"] = get_openai_embedding(doc[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving embeddings into a pickle file to save some dollars of calling repeatively \n",
    "# with open(\"gpt-embedding.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(chunked_documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0044d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt-embedding.pkl\", \"rb\") as file:\n",
    "    chunked_documents = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b319ff-e4e7-49b3-8051-73e4024f7389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert documents with embeddings into Chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Upsert documents with embeddings into Chroma\")\n",
    "for doc in tqdm(chunked_documents):\n",
    "    collection.upsert(\n",
    "        ids=[doc[\"id\"]], documents=[doc[\"text\"]], embeddings=[doc[\"embedding\"]]\n",
    "    )\n",
    "print(\"Upsert documents with embeddings into Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed8f1b-803c-4318-ad01-642f0bdbc734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
